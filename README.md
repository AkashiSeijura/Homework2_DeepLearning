Реализованно 1.1 1.2 2.1 и на половину 2.2 ( столкнулся с трудностями )

В коде "homework_model_modification.py" я реализовал l1_lambda и l2_lambda — это коэффициенты, которые определяют, насколько сильно будет применяться L1 и L2 регуляризация. Если они равны 0, регуляризация не применяется. Регуляризация применяется в методе backward, где вычисляются градиенты для весов (w) и смещения (b), поставил по умолчанию 0.01, думаю оптимальное значение, конечно можно сделать рассчёты, и посмотреть лучший вариант, где модель не переобучается, либо модель менее гибкой будет.


Остановкой я назначил early_stopping_patience = 10: Это количество эпох, в течение которых программа ждёт, если loss не уменьшается, обучение останавливается. 
patience_counter = 0: Счётчик, который отслеживает, сколько эпох прошло без улучшения ошибки.
пошёл от обратного где best_loss = float('inf') назначил лучшую ошибку бесконечность.



реализовал в utils отельную функцию для удобства make_classification_data
X, y = make_classification_data(n=200, num_classes=3, n_features=2)
y = y.argmax(dim=1) if y.ndim > 1 else y
Этот код проверяет, не представлены ли метки классов в формате one-hot (например, [0, 1, 0] для класса 1). Если да, `argmax(dim=1)` преобразует их в индексы классов (0, 1 или 2)
ClassificationDataset: Организует данные ( X ) и ( y ) в формате, удобном для PyTorch.
DataLoader: Разбивает данные на батчи по 32 ну и также перемешиваем с помощью шафлинга
model: Создаёт модель логистической регрессии с 2 входными признаками и 3 классами.
optimizer = optim.SGD(model.parameters(), lr=1): Оптимизатор SGD (стохастический градиентный спуск) обновляет веса модели, используя градиенты, чтобы минимизировать функцию потерь. lr=1 — это скорость обучения, которая контролирует, насколько сильно обновляются веса ( лучше ставить 0.01 )

optimizer.zero_grad(): Обнуляет градиенты перед новым вычислением, чтобы старые градиенты не мешали
loss = criterion(logits, batch_y): Вычисляет функцию потерь, сравнивая логиты (выход модели) с правильными метками

в моем коде метрики оценивают качество модели:
Precision: Доля правильных предсказаний среди всех предсказанных для каждого класса.
Recall: Доля правильно найденных примеров каждого класса среди всех примеров этого класса.
F1-score: Среднее гармоническое между precision и recall, баланс между ними.
ROC-AUC: Показывает, насколько хорошо модель различает классы, основываясь на вероятностях (здесь используются one-hot кодировки для многоклассового случая).
Confusion Matrix: Таблица, показывающая, сколько примеров каждого класса были правильно или неправильно классифицированы.
в моем случае метрики помогают понять, насколько модель точна, сбалансирована и устойчива. Confusion matrix визуально показывает, где модель ошибается (например, путает класс 0 с классом 1)

cat_indices = [header.index(col) for col in self.categorical_columns if col in header]
Определяем, какие колонки являются категориальными, чтобы потом закодировать их (например, Species в датасете рыб). ( для задания 2.2 )
Превращаем строковые значения категорий (например, 'Bream', 'Roach') в вектора признаков:
'Bream' → [1, 0, 0, ...]
'Roach' → [0, 1, 0, ...]
Это нужно, чтобы модель могла воспринимать категориальные данные как числа.

try:
    self.targets = torch.tensor([float(y) for y in raw_target], dtype=torch.float32)
except ValueError:
Если target — число (например, Weight в задаче регрессии) → просто превращаем в float32.


в 2.2 столкнулся с проблемой обучения. и бросил, довольно сложно и не понятно как-то стало. Либо где-то расчёты, либо что-то другое, использовал обучение в шаге 0.1 и до 1000 эпох, что мб лучше.
